import numpy as np
import h5py
import json
import tensorflow as tf
from data_generator import align, VQA_data_generator


# The only code I took from
# Doyup Lee. Unofficial tensorflow implementation of ”bottom-up and top-down attention for VQA” (tf v.1.13).
# Avaliable at https://github.com/LeeDoYup/bottom-up-attention-tf (16/10/2020), 2020
# It takes in the number of occurrences and calculates the soft score
def soft_score(occurrences):
    if occurrences == 0:
        return 0
    elif occurrences == 1:
        return 0.3
    elif occurrences == 2:
        return 0.6
    elif occurrences == 3:
        return 0.9
    else:
        return 1


def get_to_sparse_answer_vector(string, actual_answer):
    """
    Returns a sparse vector mapping each answer to its soft score

    Parameters:
        string (str): The string representation of the answer to occurrence mapping
        actual_answer (str): The ground truth answer provided in the dataset

    Returns:
        A dict object mapping answers with non-zero soft scores to soft scores
    """
    sparse_vector = {}
    string = string.decode('ascii')
    answer_mapping = string.split(";")

    if answer_mapping == ['']:
        return sparse_vector
    for answer in answer_mapping:
        a = answer.split(",")
        index = int(a[0]) - 1
        occurrences = int(a[1])
        sparse_vector[index] = soft_score(occurrences)
    sparse_vector[actual_answer - 1] = 1
    return sparse_vector


def sparse_to_full(sparse_vector):
    """
    Takes in a sparse answer vector generated by get_to_sparse_answer_vector

    Parameters:
        sparse_vector (dict): The dictionary mapping index to soft score

    Returns:
        A (3000,) numpy array each index mapping to answer soft score
    """
    vector = np.zeros(3000)
    for answer, score in sparse_vector.items():
        if answer < 3000:
            vector[answer] = score
    return vector


class VQA_soft_data_generator(VQA_data_generator):

    def get_data(self):
        """
        Loads the questions, images and answers from the input dataset
        """
        self.dataset = {}
        self.data = {}
        with open(self.input_json) as data_file:
            d = json.load(data_file)
        for key in d.keys():
            self.dataset[key] = d[key]

        with h5py.File(self.input_h5, 'r') as hf:
            # Ching-Yao Chuang. Tensorflow implementation of deeper LSTM+ normalized CNN for visual question answering.
            # Available at https://github.com/chingyaoc/VQA-tensorflow (16/10/2020), 2017.
            # Used for retrieving data from h5 file
            temp = hf.get('ques_' + self.__mode)
            self.data['questions'] = np.array(temp)

            temp = hf.get('ques_length_' + self.__mode)
            self.data['length_q'] = np.array(temp)

            temp = hf.get('img_pos_' + self.__mode)
            self.data['img_list'] = np.array(temp) - 1

            temp_ans_more = hf.get('ans_more_' + self.__mode)
            temp_ans = hf.get('ans_' + self.__mode)
            self.data['answers'] = [get_to_sparse_answer_vector(string, ans)
                                    for string, ans in zip(temp_ans_more, temp_ans)]

            temp = hf.get('question_id_' + self.__mode)
            self.data['question_id_test'] = np.array(temp)
            self.data['questions'] = align(self.data['questions'],
                                           self.data['length_q'],
                                           self.max_length)

    def __init__(self, input_json, input_h5, train=True,
                 batch_size=500, shuffle=True, feature_object=None, max_length=26):
        self.batch_size = batch_size
        self.shuffle = shuffle
        self.input_json = input_json
        self.input_h5 = input_h5
        if train:
            self.__mode = 'train'
        else:
            self.__mode = 'test'
        self.max_length = max_length
        self.get_data()
        self.on_epoch_end()
        self.__unique_features = feature_object

    def __getitem__(self, idx):
        questions = np.array(self.data['questions'][
                             idx * self.batch_size:(idx + 1) * self.batch_size])
        image_list = self.data['img_list'][
                     idx * self.batch_size:(idx + 1) * self.batch_size]
        answers_sparse = self.data['answers'][
                         idx * self.batch_size:(idx + 1) * self.batch_size]
        answers = np.array([sparse_to_full(answer) for answer in answers_sparse])
        image_features = np.array(
            [self.__unique_features.get(i) for i in image_list])

        return [image_features, questions], answers